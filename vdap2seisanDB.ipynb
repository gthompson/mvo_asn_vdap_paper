{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><u>SUDS/HYPO71 to MiniSEED/Seisan database converter</u></h1>\n",
    "<p>This Python3 notebook demonstrates how to convert a set of files from the 1990s VDAP system. For each event, the following files were generated:</p>\n",
    "\n",
    "<ul>\n",
    "<li>YYMMDDCC.WVM - SUDS multiplexed waveform file (generated by XDETECT)\n",
    "<li>YYMMDDCC.DMX - SUDS demultiplexed waveform file\n",
    "<li>YYMMDDCC.PHA - HYPO71 phase pick file (generated by SUDSPick/BUDSPick)\n",
    "<li>YYMMDDCC.PUN - HYPO71 summary file\n",
    "</ul>\n",
    "\n",
    "<p>SUDS files are converted to SAC files and then MiniSEED (direct conversion often doesn't work). MiniSEED files are then registered into a Seisan database, and a Seisan S-file (in the so-called \"Nordic\" format) is generated.</p>\n",
    "\n",
    "<p>HYPO71 phase and summary files are converted and added into the Seisan S-file.</p>\n",
    "\n",
    "<h3>Requirements:</h3>\n",
    "<p>Win-SUDS Utilities (for programs demux.exe, irig.exe and sud2sac.exe) and ObsPy. Win-SUDS is included in this repository under WINAPPS/winsuds/. Win-SUDS must be run on a Windows PC (Windows 10 64-bit worked fine in December 2019).</p>\n",
    "\n",
    "<h3>Multiple files?</h3>\n",
    "<p>For multiple events (e.g. the entire MVO database of ~230,000 events), use the Python program vdap2seisanDB.py.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do all library imports first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy.core as op\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up all paths that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths setup okay\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "WINSUDSPATH = os.path.join(cwd,'winsuds','bin')\n",
    "SUDSbasename = '95080203'\n",
    "WVMfile = SUDSbasename + '.WVM' # the original multiplexed PC-SUDS format event waveform file\n",
    "DMXfile = SUDSbasename + '.DMX' # produced by demux.exe and irig.exe\n",
    "SACbasename = SUDSbasename + '.sac' # produced  by sud2sac.exe\n",
    "MSEEDfile1 = SUDSbasename + '.ms' # produced by sud2msed.exe\n",
    "MSEEDfile2 = SUDSbasename + '.mseed' # produced by recombining SAC file\n",
    "PHAfile = SUDSbasename + '.PHA' # this might exist if HYPO71 was run to locate the event\n",
    "PUNfile = SUDSbasename + '.PUN' # this might exist if HYPO71 was run and generated a hypocenter\n",
    "demux = os.path.join(WINSUDSPATH, 'demux.exe')\n",
    "irig = os.path.join(WINSUDSPATH, 'irig.exe')\n",
    "sud2sac = os.path.join(WINSUDSPATH, 'sud2sac.exe')\n",
    "sud2msed = os.path.join(WINSUDSPATH, 'sud2msed.exe')\n",
    "print('Paths setup okay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that WVM files cannot be read by ObsPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ObsPy cannot read multiplexed SUDS format\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    st = op.read(WVMfile)\n",
    "except:\n",
    "    print('ObsPy cannot read multiplexed SUDS format')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demultiplex the WVM file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demultiplexing 95080203.WVM\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(WVMfile): # if WVM file exists, demultiplex it\n",
    "    print('Demultiplexing ' + WVMfile)\n",
    "    os.system(demux + ' ' + WVMfile)\n",
    "    print('Done')\n",
    "else:\n",
    "    print(WVMfile + ' does not exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that DMX files cannot be read by ObsPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ObsPy cannot read demultiplexed SUDS format\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    st = op.read(DMXfile)\n",
    "except:\n",
    "    print('ObsPy cannot read demultiplexed SUDS format')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time correct the DMX file and convert to SAC files. \n",
    "\n",
    "Note that we found that sud2msed does not read trace headers, it just produces one trace from many and also has an incorrect start time. This is why we use sud2sac, which we have checked against sudsplot.exe and shows the correct trace headers, waveforms and times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time correcting 95080203.DMX\n",
      "Converting 95080203.DMX to SAC files\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(DMXfile): # if DMX file exists, time correct it then convert to SAC\n",
    "    print('Time correcting ' + DMXfile)\n",
    "    os.system(irig + ' ' + DMXfile)\n",
    "    \n",
    "    # This produces one file per trace\n",
    "    print('Converting ' + DMXfile + ' to SAC files')\n",
    "    os.system(sud2sac + ' ' + DMXfile)\n",
    "    \n",
    "    # This does not produce a valid Miniseed file - it misses channel headers and combines everything into 1 trace\n",
    "    #print('Converting ' + DMXfile + ' to Miniseed file')\n",
    "    #os.system(sud2msed + ' ' + DMXfile + ' ' + MSEEDfile1)\n",
    "    \n",
    "    print('Done')\n",
    "else:\n",
    "    print(DMXfile + ' does not exist')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the SAC files into a single Miniseed file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining 95080203.sac-000 into Miniseed file 95080203.mseed\n",
      "Combining 95080203.sac-001 into Miniseed file 95080203.mseed\n",
      "Combining 95080203.sac-002 into Miniseed file 95080203.mseed\n",
      "Combining 95080203.sac-003 into Miniseed file 95080203.mseed\n",
      "Combining 95080203.sac-004 into Miniseed file 95080203.mseed\n",
      "Combining 95080203.sac-005 into Miniseed file 95080203.mseed\n",
      "Combining 95080203.sac-006 into Miniseed file 95080203.mseed\n",
      "Combining 95080203.sac-007 into Miniseed file 95080203.mseed\n",
      "Combining 95080203.sac-008 into Miniseed file 95080203.mseed\n",
      "Combining 95080203.sac-009 into Miniseed file 95080203.mseed\n",
      "Combining 95080203.sac-00A into Miniseed file 95080203.mseed\n",
      "Combining 95080203.sac-00B into Miniseed file 95080203.mseed\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Now merge the SAC files into a single valid Miniseed file    \n",
    "st = op.Stream()\n",
    "sacfilelist = glob.glob(SACbasename + '-???')\n",
    "if len(sacfilelist) > 0:\n",
    "    for sacfile in sacfilelist:\n",
    "        print('Combining ' + sacfile + ' into Miniseed file ' + MSEEDfile2)\n",
    "        tr = op.read(sacfile)\n",
    "        st = st + tr\n",
    "    st.write(MSEEDfile2)\n",
    "    print('Done')\n",
    "else:\n",
    "    print('No SAC files found matching ' + SACbasename + '*. Must have been bad DMX file ' + DMXfile)\n",
    "    fbad = open('badDMXfileList.txt','a+')\n",
    "    fbad.write(DMXfile + \"\\n\")\n",
    "    fbad.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional sanity check to re-read the Miniseed file and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st2 = op.read(MSEEDfile2)\n",
    "st2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUDSplot can be used to compare if Miniseed conversion was accurate, but will not show up from here\n",
    "#os.system('sudsplot.exe ' + DMXfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add this Miniseed event waveform file to the Seisan database.\n",
    "The Miniseed file will be moved to [SEISANTOP]/WAV/[SEISANDB]/YYYY/MM\n",
    "A corresponding Seisan S-file (event metadata file) will be created at [SEISANTOP]/REA/[SEISANDB]/YYYY/MM\n",
    "\n",
    "The Seisan programs MAKEREA and AUTOREG are used here. Since they normally require user input, we create files to simulate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seisanDBname = 'ASNE2'\n",
    "yy = SUDSbasename[0:2]\n",
    "mm = SUDSbasename[2:4]\n",
    "century = '19'\n",
    "if yy < '80':\n",
    "    century = '20'\n",
    "yyyy = century + yy\n",
    "fptr = open('makerea_wrapper.txt','w')\n",
    "fptr.write(seisanDBname + '\\n')\n",
    "fptr.write(yyyy + mm + '\\n')\n",
    "fptr.write('\\n')\n",
    "fptr.write('BOTH\\n')\n",
    "fptr.close()\n",
    "os.system('makerea < makerea_wrapper.txt')\n",
    "os.system('dirf ' + MSEEDfile2)\n",
    "fptr = open('autoreg_wrapper.txt','w')\n",
    "fptr.write('L\\n')\n",
    "fptr.write('m\\n')\n",
    "fptr.write(seisanDBname + '\\n')\n",
    "fptr.write('gt\\n')\n",
    "fptr.close()\n",
    "os.system('autoreg < autoreg_wrapper.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Seismo\\REA\\ASNE2\\1995\\08\\02-0354-19L.S199508\n",
      " 1995  8 2  354 19.4 L                                                         1\n",
      " ACTION:ARG 19-12-01 13:28 OP:gt   STATUS:               ID:19950802035419     I\n",
      " 95080203.mseed                                                                6\n",
      " STAT SP IPHASW D HRMM SECON CODA AMPLIT PERI AZIMU VELO AIN AR TRES W  DIS CAZ7\n",
      "                                                                                \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def findLatestFile(dirpath):\n",
    "    lists = os.listdir(dirpath)                                   \n",
    "    lists.sort(key=lambda fn:os.path.getmtime(os.path.join(dirpath, fn)))\n",
    "    return os.path.join(dirpath,lists[-1])\n",
    "\n",
    "def displayFile(dirpath):\n",
    "    if os.path.exists(dirpath):\n",
    "        fptr = open(dirpath, 'r')\n",
    "        str = fptr.read()\n",
    "        print(str)\n",
    "    else:\n",
    "        print(dirpath + ' not found')\n",
    "\n",
    "SFILE = findLatestFile(os.path.join(os.environ['SEISAN_TOP'],'REA',seisanDBname,yyyy,mm))\n",
    "print(SFILE)\n",
    "displayFile(SFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If BUDSPICK generated a phase picks file (file extension *.PHA), add that into the S-file using the Seisan program HYPNOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No PHA file for 95080203\n",
      " 1995  8 2  354 19.4 L                                                         1\n",
      " ACTION:ARG 19-12-01 13:28 OP:gt   STATUS:               ID:19950802035419     I\n",
      " 95080203.mseed                                                                6\n",
      " STAT SP IPHASW D HRMM SECON CODA AMPLIT PERI AZIMU VELO AIN AR TRES W  DIS CAZ7\n",
      "                                                                                \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def appendPicks(hypnoroutfile, sfilepath):\n",
    "    if os.path.exists(hypnoroutfile) and os.path.exists(sfilepath):\n",
    "        pass\n",
    "    else:\n",
    "        print('Cannot combine files, one of the inputs does not exist')\n",
    "    print(\"Appending \" + hypnoroutfile + \" to \" + sfilepath)\n",
    "    newlines = list()\n",
    "    with open(sfilepath, \"r\") as fs:\n",
    "        for line in fs:\n",
    "            #print(line[-2])\n",
    "            if line[-2] == '7':\n",
    "                print(\"- Inserting \" + hypnoroutfile)\n",
    "                #fh = open(hypnoroutfile, 'r')\n",
    "                with open(hypnoroutfile, 'r') as fh:\n",
    "                    for hnline in fh:\n",
    "                        if hnline[-2] != '1':\n",
    "                            newlines.append(hnline)\n",
    "                #str = fh.read()\n",
    "                #fh.close()\n",
    "                #newlines.append(str)\n",
    "            else:\n",
    "                newlines.append(line)\n",
    "    fs2 = open(sfilepath, \"w\")\n",
    "    for newline in newlines:\n",
    "        fs2.write(newline)\n",
    "    fs2.close()\n",
    "    return\n",
    "            \n",
    "if os.path.exists(PHAfile):\n",
    "    fptr = open('hypnor_wrapper.txt','w')\n",
    "    fptr.write(PHAfile + '\\n')\n",
    "    fptr.write(century + '\\n')\n",
    "    fptr.close()\n",
    "    displayFile('hypnor_wrapper.txt')\n",
    "    os.system('hypnor < hypnor_wrapper.txt')\n",
    "    if os.path.exists('hypnor.out'):\n",
    "        print('Running HYPNOR on ' + PHAfile)\n",
    "        appendPicks('hypnor.out', SFILE)\n",
    "        print(' - Success')\n",
    "    else:\n",
    "        print(' - Failed')\n",
    "else:\n",
    "    print('No PHA file for ' + SUDSbasename)\n",
    "displayFile(SFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting 95080203.PUN and inserting into C:\\Seismo\\REA\\ASNE2\\1995\\08\\02-0354-19L.S199508\n",
      "Could not translate HYPO71 summary file 95080203.PUN\n",
      " DATE    ORIGIN    LAT N    LONG W    DEPTH    MAG NO GAP DMIN  RMS  ERH  ERZ QM\n",
      "950802  354 46.73 16-38.95  62- 8.33  17.20         7 318  6.1 0.04  7.8 10.6 D1\n",
      "\n",
      " 1995  8 2  354 19.4 L                                                         1\n",
      " ACTION:ARG 19-12-01 13:28 OP:gt   STATUS:               ID:19950802035419     I\n",
      " 95080203.mseed                                                                6\n",
      " STAT SP IPHASW D HRMM SECON CODA AMPLIT PERI AZIMU VELO AIN AR TRES W  DIS CAZ7\n",
      "                                                                                \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def HSUMNOR(PUNfile):\n",
    "    # Based on hsumnor.for in Seisan (which did not work, but this does!)\n",
    "    # I should add something for the high accuracy lines too, as this only records origin to nearest tenth of second\n",
    "    outstr = ' ' * 79 + '1'\n",
    "    agency = 'MVO'\n",
    "    if os.path.exists(PUNfile):\n",
    "        #print('0123456789'*8)\n",
    "        #displayFile(PUNfile)\n",
    "        #print(' 1996  625 0337 32.9 L  61.588   3.495 15.1  TES 31 1.0 3.2LTES 3.0CTES 3.2LNAO1') # a line from a TEST file in Seisan\n",
    "        f1 = open(PUNfile, 'r')\n",
    "        with open(PUNFile, 'r') as f1:\n",
    "            for line in f1:\n",
    "                pass\n",
    "            \n",
    "        str = line\n",
    "        #f1.read()\n",
    "        #f1.close()\n",
    "        yy = float(str[0:2].strip())\n",
    "        mm = float(str[2:4].strip())\n",
    "        dd = float(str[4:6].strip())\n",
    "        hr = float(str[7:9].strip())\n",
    "        mi = float(str[9:11].strip())\n",
    "        sec = float(str[12:17].strip())\n",
    "        lat = float(str[17:20].strip())\n",
    "        mlat = float(str[21:26].strip())\n",
    "        lon = float(str[27:30].strip())\n",
    "        mlon = float(str[31:36].strip())\n",
    "        depth = float(str[37:43].strip())\n",
    "        magstr = str[45:49].strip()\n",
    "        try:\n",
    "            magstr = \"%3.1f\" % float(magstr)\n",
    "        except:\n",
    "            magstr = \" \" * 3\n",
    "        nphase = float(str[50:53].strip())\n",
    "        rms = float(str[62:66].strip())\n",
    "        dlat = float(lat) + float(mlat)/60.0\n",
    "        dlon = float(lon) + float(mlon)/60.0\n",
    "        if yy < 80:\n",
    "            cen = 20\n",
    "        else:\n",
    "            cen = 19\n",
    "        newstr = ' %2d%02d %02d%02d %02d%02d %4.1f L ' % (cen,yy,mm,dd,hr,mi,sec)    \n",
    "        newstr = newstr + '%7.3f%8.3f%5.1f  %s%3d%4.1f %s' % (dlat, dlon, depth, agency, nphase, rms, magstr)\n",
    "        outstr = newstr + outstr[len(newstr):]\n",
    "    return outstr\n",
    "\n",
    "def insertHYPO71Summary(PUNfile, sfilepath):\n",
    "    if os.path.exists(PUNfile) and os.path.exists(sfilepath):\n",
    "        pass\n",
    "    else:\n",
    "        print('Cannot combine files, one of the inputs does not exist')\n",
    "    print(\"Converting \" + PUNfile + \" and inserting into \" + sfilepath)\n",
    "    newlines = list()\n",
    "    hypo71sumstr = HSUMNOR(PUNfile)\n",
    "    if hypo71sumstr != \"\":\n",
    "        newlines.append(hypo71sumstr + \"\\n\")\n",
    "    with open(sfilepath, \"r\") as fs:\n",
    "        for line in fs:\n",
    "            newlines.append(line)\n",
    "    fs2 = open(sfilepath, \"w\")\n",
    "    for newline in newlines:\n",
    "        fs2.write(newline)\n",
    "    fs2.close()\n",
    "    return\n",
    "\n",
    "if os.path.exists(PUNfile):\n",
    "    \n",
    "    try:\n",
    "        insertHYPO71Summary(PUNfile, SFILE)\n",
    "    except:\n",
    "        print('Could not translate HYPO71 summary file %s' % PUNfile)\n",
    "        displayFile(PUNfile)\n",
    "    displayFile(SFILE)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting 95080203.PUN and inserting into C:\\Seismo\\REA\\ASNE2\\1995\\08\\02-0354-19L.S199508\n",
      "Converting 95080203.PUN and inserting into C:\\Seismo\\REA\\ASNE2\\1995\\08\\02-0354-19L.S199508\n",
      " 1995 0802 0354 46.7 L  16.649  62.139 17.2  MVO  7 0.0                        1\n",
      " 1995 0802 0354 46.7 L  16.649  62.139 17.2  MVO  7 0.0                        1\n",
      " 1995  8 2  354 19.4 L                                                         1\n",
      " ACTION:ARG 19-12-01 13:28 OP:gt   STATUS:               ID:19950802035419     I\n",
      " 95080203.mseed                                                                6\n",
      " STAT SP IPHASW D HRMM SECON CODA AMPLIT PERI AZIMU VELO AIN AR TRES W  DIS CAZ7\n",
      "                                                                                \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def HSUMNOR(PUNfile):\n",
    "    # Based on hsumnor.for in Seisan (which did not work, but this does!)\n",
    "    # I should add something for the high accuracy lines too, as this only records origin to nearest tenth of second\n",
    "    outstr = ' ' * 79 + '1'\n",
    "    agency = 'MVO'\n",
    "    if os.path.exists(PUNfile):\n",
    "        #print('0123456789'*8)\n",
    "        #displayFile(PUNfile)\n",
    "        #print(' 1996  625 0337 32.9 L  61.588   3.495 15.1  TES 31 1.0 3.2LTES 3.0CTES 3.2LNAO1') # a line from a TEST file in Seisan\n",
    "        with open(PUNfile, 'r') as f1:\n",
    "            for line in f1:\n",
    "                pass      \n",
    "        str = line\n",
    "        yy = float(str[0:2].strip())\n",
    "        mm = float(str[2:4].strip())\n",
    "        dd = float(str[4:6].strip())\n",
    "        hr = float(str[7:9].strip())\n",
    "        mi = float(str[9:11].strip())\n",
    "        sec = float(str[12:17].strip())\n",
    "        lat = float(str[17:20].strip())\n",
    "        mlat = float(str[21:26].strip())\n",
    "        lon = float(str[27:30].strip())\n",
    "        mlon = float(str[31:36].strip())\n",
    "        depth = float(str[37:43].strip())\n",
    "        magstr = str[45:49].strip()\n",
    "        try:\n",
    "            magstr = \"%3.1f\" % float(magstr)\n",
    "        except:\n",
    "            magstr = \" \" * 3\n",
    "        nphase = float(str[50:53].strip())\n",
    "        rms = float(str[62:66].strip())\n",
    "        dlat = float(lat) + float(mlat)/60.0\n",
    "        dlon = float(lon) + float(mlon)/60.0\n",
    "        if yy < 80:\n",
    "            cen = 20\n",
    "        else:\n",
    "            cen = 19\n",
    "        newstr = ' %2d%02d %02d%02d %02d%02d %4.1f L ' % (cen,yy,mm,dd,hr,mi,sec)    \n",
    "        newstr = newstr + '%7.3f%8.3f%5.1f  %s%3d%4.1f %s' % (dlat, dlon, depth, agency, nphase, rms, magstr)\n",
    "        outstr = newstr + outstr[len(newstr):]\n",
    "    return outstr\n",
    "\n",
    "def insertHYPO71Summary(PUNfile, sfilepath):\n",
    "    if os.path.exists(PUNfile) and os.path.exists(sfilepath):\n",
    "        pass\n",
    "    else:\n",
    "        print('Cannot combine files, one of the inputs does not exist')\n",
    "    print(\"Converting \" + PUNfile + \" and inserting into \" + sfilepath)\n",
    "    newlines = list()\n",
    "    hypo71sumstr = HSUMNOR(PUNfile)\n",
    "    if hypo71sumstr != \"\":\n",
    "        newlines.append(hypo71sumstr + \"\\n\")\n",
    "    with open(sfilepath, \"r\") as fs:\n",
    "        for line in fs:\n",
    "            newlines.append(line)\n",
    "    fs2 = open(sfilepath, \"w\")\n",
    "    for newline in newlines:\n",
    "        fs2.write(newline)\n",
    "    fs2.close()\n",
    "    return\n",
    "\n",
    "if os.path.exists(PUNfile):\n",
    "    try:\n",
    "        insertHYPO71Summary(PUNfile, SFILE)\n",
    "    except:\n",
    "        print('Could not translate HYPO71 summary file %s' % PUNfile)\n",
    "        displayFile(PUNfile)\n",
    "    displayFile(SFILE)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What remains to be done:\n",
    "3. Some DMX files seem to be broken. Are these the ones copied over? Check 9508264I. Check ASNE_/1995/08/ * 1995/08 since these from two different copying processes.\n",
    "6. make the list of number of files each day from the last event label of each day\n",
    "7. Add DOI's for dataset and software & create github project\n",
    "8. process bad???fileList.txt. For bad DMX files, I can check if WVM file exists and if so, convert. Otherwise, see if a valid miniseed file exists in gse_all on newton - but beware that it has not been shifted by 4 hours. Bad PUN files should now work, but I need to figure out how to add them. Would need to write in a way that works even if WVM and DMX file not found.\n",
    "9. Go through whole summary hypo71 list, and try to associate with any event it overlaps with. Easiest to do this in ObsPy. \n",
    "10. Go through the sheets I am carrying around.\n",
    "\n",
    "Modify script so that we do not run makerea each time\n",
    "\n",
    "Things for later:\n",
    "* do I need to apply 4 hour time shift (+4)?\n",
    "* remove duplicate S-files\n",
    "* merge with the student teaching cluster database. S-files should have same name (or be within a second). Grab the classification parts and add them. Or go the other way - adding any location/phase pick lines. Beware of 4 hour time difference.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95080203.DMX\n"
     ]
    }
   ],
   "source": [
    "print(DMXfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'95080203.mseed'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = os.path.join('fred','bill','1995','07', DMXfile)\n",
    "os.path.basename(f)[0:-4] + '.mseed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
